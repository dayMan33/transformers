{
    "os": "Linux-5.10.104-aufs-3-x86_64-with-debian-10.10",
    "python": "3.7.3",
    "heartbeatAt": "2022-11-10T15:48:40.101950",
    "startedAt": "2022-11-10T15:48:37.978838",
    "docker": null,
    "gpu": "NVIDIA A10",
    "gpu_count": 1,
    "cpu_count": 32,
    "cuda": null,
    "args": [
        "--model_name_or_path",
        "bert-large-cased",
        "--task_name",
        "sst2",
        "--seed",
        "0",
        "--per_device_train_batch_size",
        "32",
        "--per_device_eval_batch_size",
        "1",
        "--do_eval",
        "--do_train",
        "--max_seq_length",
        "256",
        "--max_train_samples",
        "600",
        "--output_dir",
        "/cs/labs/roys/danielrotem/HF_sledgehammer/output/bert-large-cased/sst2/baseline/seed_0",
        "--cache_dir",
        "/cs/labs/roys/danielrotem/HF_sledgehammer/cache/BERT-larger",
        "--learning_rate",
        "2e-5",
        "--disable_tqdm",
        "true",
        "--evaluation_strategy",
        "no",
        "--save_strategy",
        "no",
        "--save_total_limit",
        "0",
        "--overwrite_output_dir",
        "--max_steps",
        "100"
    ],
    "state": "running",
    "program": "run_glue_clean.py",
    "codePath": "examples/pytorch/text-classification/run_glue_clean.py",
    "git": {
        "remote": "https://github.com/huggingface/transformers.git",
        "commit": "ccc089780415445768bcfd3ac4418cec20353484"
    },
    "email": "daniel.rotem@mail.huji.ac.il",
    "root": "/cs/labs/roys/danielrotem/HF_sledgehammer/transformers",
    "host": "ampere-01",
    "username": "danielrotem",
    "executable": "/cs/labs/roys/danielrotem/venvs/sledge_venv/bin/python3"
}
